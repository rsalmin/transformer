
# -*- coding: utf-8 -*-
"""transformer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb

##### Copyright 2019 The TensorFlow Authors.

##### Modified by Roman.Salmin@gmail.com
"""
import tensorflow as tf

import tensorflow_datasets as tfds

import numpy as np
import os
#examples, metadata = tfds.load('ted_hrlr_translate/ru_to_en', with_info=True,
#                               as_supervised=True)
#train_examples, val_examples = examples['train'], examples['validation']
#print(examples, metadata)
#print('train examples', train_examples)
#for ru, en in val_examples:
#    print(ru, en)

dataPath = 'data'

en_train = tf.data.TextLineDataset(os.path.join(dataPath, 'en.train'))
ru_train = tf.data.TextLineDataset(os.path.join(dataPath, 'ru.train'))
train_examples = tf.data.Dataset.zip((ru_train, en_train))

en_valid = tf.data.TextLineDataset(os.path.join(dataPath, 'en.dev'))
ru_valid = tf.data.TextLineDataset(os.path.join(dataPath, 'ru.dev'))
valid_examples = tf.data.Dataset.zip((ru_valid, en_valid))

tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(
                     (en.numpy() for en in en_train), target_vocab_size=2**15)
tokenizer_en.save_to_file('data/tokenizer_en')

tokenizer_ru = tfds.features.text.SubwordTextEncoder.build_from_corpus(
                     (ru.numpy() for ru in ru_train), target_vocab_size=2**15)
tokenizer_ru.save_to_file('data/tokenizer_ru')
